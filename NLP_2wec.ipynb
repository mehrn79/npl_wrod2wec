{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mehrn79/npl_wrod2wec/blob/main/NLP_2wec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AErZn51Q2h5x"
      },
      "source": [
        "# **Word2wec implementation using skip-grams**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WADfIeK-1T_D"
      },
      "source": [
        "##**Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyONJYsR1qXi"
      },
      "source": [
        "### **librarys for preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "askzrES_54hc"
      },
      "outputs": [],
      "source": [
        "pip install hazm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "R1t95jwN25P8"
      },
      "outputs": [],
      "source": [
        "from __future__ import unicode_literals\n",
        "from hazm import *\n",
        "from keras.preprocessing import text\n",
        "from keras.preprocessing.sequence import skipgrams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxuszyHl3eQz"
      },
      "source": [
        "### **getting our corpes and stop words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "LTDxjaSzJazK"
      },
      "outputs": [],
      "source": [
        "with open('/content/shams.txt') as f:\n",
        "  lines = f.readlines()\n",
        "\n",
        "with open('/content/stopwords.txt') as file:\n",
        "  stopLines = file.readlines()\n",
        "stopWord = [item.replace('\\n',\"\") for item in stopLines]\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMjciJZD39CN"
      },
      "source": [
        "### **cleaning our corpes by stop words**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "1jjQItM2PfpF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c7086a-88b3-45e4-9df5-9a3f759e1ed2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "رضای آدم گریست سیصد خنده وصلش گشاده گشت دهن\n"
          ]
        }
      ],
      "source": [
        "words= []\n",
        "for sent in lines :\n",
        "   words.append(word_tokenize(sent))\n",
        "\n",
        "corpes=[]\n",
        "for wordSent in words :\n",
        "  cleanSent=[]\n",
        "  for word in wordSent :\n",
        "    if word not in stopWord :\n",
        "      cleanSent.append(word)\n",
        "  if(len(cleanSent)>1) :\n",
        "    corpes.append(' '.join(cleanSent))\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUswmtBp42Am"
      },
      "source": [
        "### **tokenize our corpes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "sQ_hdg3iM7Eb"
      },
      "outputs": [],
      "source": [
        "tokenizer = text.Tokenizer()\n",
        "tokenizer.fit_on_texts(corpes)\n",
        "\n",
        "word2id = tokenizer.word_index\n",
        "id2word = {v:k for k, v in word2id.items()}\n",
        "\n",
        "vocab_size = len(word2id) + 1 \n",
        "embed_size = 100\n",
        "\n",
        "sentencesID = [[word2id[w] for w in text.text_to_word_sequence(doc)] for doc in corpes]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bgG68Stu5Uu_"
      },
      "source": [
        "### **generate skip-grams**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "xaVL7hq2sB3i"
      },
      "outputs": [],
      "source": [
        "skip_grams = [skipgrams(sentID, vocabulary_size=vocab_size, window_size=2) for sentID in sentencesID]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvmV1_FXGPRV"
      },
      "source": [
        "## **Build the skip-gram model architecture**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bytYaGCGj9B"
      },
      "source": [
        "### **librarys for skip-gram model architecture**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "ig5xuWPFGbMp"
      },
      "outputs": [],
      "source": [
        " from keras.preprocessing.sequence import skipgrams \n",
        " from keras.layers import *\n",
        " from keras.layers.core import Dense, Reshape\n",
        " from keras.layers.embeddings import Embedding\n",
        " from keras.models import Model,Sequential \n",
        " import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdGirKbrGxDk"
      },
      "source": [
        "### **implementation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIrPvPB9G3Xl",
        "outputId": "d93db373-3c9e-442f-b91a-a5b2ec1423d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " embedding_30_input (InputLayer  [(None, 1)]         0           []                               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding_31_input (InputLayer  [(None, 1)]         0           []                               \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " embedding_30 (Embedding)       (None, 1, 100)       983400      ['embedding_30_input[0][0]']     \n",
            "                                                                                                  \n",
            " embedding_31 (Embedding)       (None, 1, 100)       983400      ['embedding_31_input[0][0]']     \n",
            "                                                                                                  \n",
            " reshape_30 (Reshape)           (None, 100)          0           ['embedding_30[0][0]']           \n",
            "                                                                                                  \n",
            " reshape_31 (Reshape)           (None, 100)          0           ['embedding_31[0][0]']           \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 100)          0           ['reshape_30[0][0]',             \n",
            "                                                                  'reshape_31[0][0]']             \n",
            "                                                                                                  \n",
            " sequential_47 (Sequential)     (None, 1)            101         ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,966,901\n",
            "Trainable params: 1,966,901\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "targetWord_model = Sequential()\n",
        "targetWord_model.add(Embedding(vocab_size, embed_size,\n",
        "                         embeddings_initializer=\"glorot_uniform\",\n",
        "                         input_length=1))\n",
        "targetWord_model.add(Reshape((embed_size, )))\n",
        "\n",
        "contextWord_model = Sequential()\n",
        "contextWord_model.add(Embedding(vocab_size, embed_size,\n",
        "                  embeddings_initializer=\"glorot_uniform\",\n",
        "                  input_length=1))\n",
        "contextWord_model.add(Reshape((embed_size,)))\n",
        "\n",
        "\n",
        "\n",
        "merged_output = add([targetWord_model.output, contextWord_model.output]) \n",
        "model_combined = Sequential()\n",
        "model_combined.add(Dense(1, kernel_initializer=\"glorot_uniform\", activation=\"sigmoid\"))\n",
        "final_model = Model([targetWord_model.input, contextWord_model.input], model_combined(merged_output))\n",
        "final_model.compile(loss=\"mean_squared_error\", optimizer=\"Adam\")\n",
        "final_model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rmwItZhIXkWc"
      },
      "source": [
        "## **train the model**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pU9GQWTu-QDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FpJa_0fvXqKQ",
        "outputId": "175d21ee-c1eb-4a0a-fec2-c12692971759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 1 Loss: 1047.8232188560069\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 2 Loss: 909.7456455137581\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 3 Loss: 822.9532449673861\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 4 Loss: 756.4855859400705\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 5 Loss: 712.5904396534897\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 6 Loss: 681.6832656539045\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 7 Loss: 659.4706270527095\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 8 Loss: 641.9601009683684\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 9 Loss: 627.7781069034245\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 10 Loss: 616.2313599949703\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 11 Loss: 607.2489358967869\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 12 Loss: 599.7268545523984\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 13 Loss: 594.0223763033864\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 14 Loss: 589.0359229201276\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 15 Loss: 585.6143119881308\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 16 Loss: 582.2023130514863\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 17 Loss: 580.9331315423478\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 18 Loss: 578.9206317325297\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 19 Loss: 577.993001607043\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 20 Loss: 576.6141010578431\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 21 Loss: 576.9038514110725\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 22 Loss: 575.7797937006544\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 23 Loss: 575.8760586449571\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 24 Loss: 574.9540234332089\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 25 Loss: 574.2161167429695\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n",
            "Epoch: 26 Loss: 573.4050724729095\n",
            "Processed 0 (skip_first, skip_second, relevance) pairs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-67978c5149d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m          \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m              \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Processed {} (skip_first, skip_second, relevance) pairs'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m          \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mfinal_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m      \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2086\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2087\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2088\u001b[0;31m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2089\u001b[0m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[1;32m   2090\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_trainable_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m       if (layer in self._current_trainable_state and\n\u001b[0;32m--> 148\u001b[0;31m           trainable != self._current_trainable_state[layer]):\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_set_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/weakref.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "for epoch in range(1, 50):\n",
        "     loss = 0\n",
        "     for i, elem in enumerate(skip_grams):\n",
        "         pair_first_elem = np.array(list(zip(*elem[0]))[0], dtype='int32')\n",
        "         pair_second_elem = np.array(list(zip(*elem[0]))[1], dtype='int32')\n",
        "         labels = np.array(elem[1], dtype='int32')\n",
        "         X = [pair_first_elem, pair_second_elem]\n",
        "         Y = labels\n",
        "         if i % 10000 == 0:\n",
        "             print('Processed {} (skip_first, skip_second, relevance) pairs'.format(i))\n",
        "         loss += final_model.train_on_batch(X,Y)  \n",
        "\n",
        "     print('Epoch:', epoch, 'Loss:', loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KtDNmTHSqL6"
      },
      "source": [
        "## **getting word embeddings**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "iWfVuZJ4S3yq",
        "outputId": "fc13b1b1-1ebc-4ed0-90db-2cb8a73ba29a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9833, 100)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0         1         2         3         4         5         6   \\\n",
              "جان  -0.053558 -0.163965 -0.050072 -0.174307  0.020303  0.023441 -0.012687   \n",
              "دل    0.077389 -0.125550  0.038674 -0.024768 -0.131657  0.106669  0.147769   \n",
              "عشق  -0.008767 -0.191138 -0.127382 -0.086471  0.141952  0.032412 -0.083442   \n",
              "جهان -0.201111  0.043621  0.125963  0.159922 -0.277500 -0.002178 -0.023111   \n",
              "اندر  0.029862  0.031981 -0.081911  0.060354  0.072531 -0.018876  0.104680   \n",
              "\n",
              "            7         8         9   ...        90        91        92  \\\n",
              "جان   0.159729 -0.090239 -0.108262  ... -0.187364 -0.010242  0.126306   \n",
              "دل   -0.071099  0.129209  0.020927  ... -0.058013  0.123520 -0.020460   \n",
              "عشق   0.073681 -0.068220 -0.069479  ... -0.277621  0.042796  0.127504   \n",
              "جهان -0.042849 -0.181581 -0.113298  ... -0.001987  0.097173  0.002007   \n",
              "اندر -0.045227  0.009120 -0.139848  ...  0.004520  0.301435  0.100419   \n",
              "\n",
              "            93        94        95        96        97        98        99  \n",
              "جان   0.054474 -0.136347 -0.011369  0.072804  0.080109 -0.167982  0.002764  \n",
              "دل    0.094458  0.080051  0.007871 -0.022510  0.096668 -0.038876  0.233341  \n",
              "عشق   0.021125  0.033599  0.204628 -0.087292  0.067262 -0.211242 -0.015171  \n",
              "جهان -0.132032 -0.230522 -0.171756  0.196306 -0.051702 -0.193303  0.223304  \n",
              "اندر  0.176141  0.126837  0.106736  0.292485 -0.060127 -0.082429  0.010457  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-57ce9578-ebc8-44a4-950e-30e6c5285bd3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>جان</th>\n",
              "      <td>-0.053558</td>\n",
              "      <td>-0.163965</td>\n",
              "      <td>-0.050072</td>\n",
              "      <td>-0.174307</td>\n",
              "      <td>0.020303</td>\n",
              "      <td>0.023441</td>\n",
              "      <td>-0.012687</td>\n",
              "      <td>0.159729</td>\n",
              "      <td>-0.090239</td>\n",
              "      <td>-0.108262</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.187364</td>\n",
              "      <td>-0.010242</td>\n",
              "      <td>0.126306</td>\n",
              "      <td>0.054474</td>\n",
              "      <td>-0.136347</td>\n",
              "      <td>-0.011369</td>\n",
              "      <td>0.072804</td>\n",
              "      <td>0.080109</td>\n",
              "      <td>-0.167982</td>\n",
              "      <td>0.002764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>دل</th>\n",
              "      <td>0.077389</td>\n",
              "      <td>-0.125550</td>\n",
              "      <td>0.038674</td>\n",
              "      <td>-0.024768</td>\n",
              "      <td>-0.131657</td>\n",
              "      <td>0.106669</td>\n",
              "      <td>0.147769</td>\n",
              "      <td>-0.071099</td>\n",
              "      <td>0.129209</td>\n",
              "      <td>0.020927</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.058013</td>\n",
              "      <td>0.123520</td>\n",
              "      <td>-0.020460</td>\n",
              "      <td>0.094458</td>\n",
              "      <td>0.080051</td>\n",
              "      <td>0.007871</td>\n",
              "      <td>-0.022510</td>\n",
              "      <td>0.096668</td>\n",
              "      <td>-0.038876</td>\n",
              "      <td>0.233341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>عشق</th>\n",
              "      <td>-0.008767</td>\n",
              "      <td>-0.191138</td>\n",
              "      <td>-0.127382</td>\n",
              "      <td>-0.086471</td>\n",
              "      <td>0.141952</td>\n",
              "      <td>0.032412</td>\n",
              "      <td>-0.083442</td>\n",
              "      <td>0.073681</td>\n",
              "      <td>-0.068220</td>\n",
              "      <td>-0.069479</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.277621</td>\n",
              "      <td>0.042796</td>\n",
              "      <td>0.127504</td>\n",
              "      <td>0.021125</td>\n",
              "      <td>0.033599</td>\n",
              "      <td>0.204628</td>\n",
              "      <td>-0.087292</td>\n",
              "      <td>0.067262</td>\n",
              "      <td>-0.211242</td>\n",
              "      <td>-0.015171</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>جهان</th>\n",
              "      <td>-0.201111</td>\n",
              "      <td>0.043621</td>\n",
              "      <td>0.125963</td>\n",
              "      <td>0.159922</td>\n",
              "      <td>-0.277500</td>\n",
              "      <td>-0.002178</td>\n",
              "      <td>-0.023111</td>\n",
              "      <td>-0.042849</td>\n",
              "      <td>-0.181581</td>\n",
              "      <td>-0.113298</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.001987</td>\n",
              "      <td>0.097173</td>\n",
              "      <td>0.002007</td>\n",
              "      <td>-0.132032</td>\n",
              "      <td>-0.230522</td>\n",
              "      <td>-0.171756</td>\n",
              "      <td>0.196306</td>\n",
              "      <td>-0.051702</td>\n",
              "      <td>-0.193303</td>\n",
              "      <td>0.223304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>اندر</th>\n",
              "      <td>0.029862</td>\n",
              "      <td>0.031981</td>\n",
              "      <td>-0.081911</td>\n",
              "      <td>0.060354</td>\n",
              "      <td>0.072531</td>\n",
              "      <td>-0.018876</td>\n",
              "      <td>0.104680</td>\n",
              "      <td>-0.045227</td>\n",
              "      <td>0.009120</td>\n",
              "      <td>-0.139848</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004520</td>\n",
              "      <td>0.301435</td>\n",
              "      <td>0.100419</td>\n",
              "      <td>0.176141</td>\n",
              "      <td>0.126837</td>\n",
              "      <td>0.106736</td>\n",
              "      <td>0.292485</td>\n",
              "      <td>-0.060127</td>\n",
              "      <td>-0.082429</td>\n",
              "      <td>0.010457</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-57ce9578-ebc8-44a4-950e-30e6c5285bd3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-57ce9578-ebc8-44a4-950e-30e6c5285bd3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-57ce9578-ebc8-44a4-950e-30e6c5285bd3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "import pandas as pd                     \n",
        "from scipy.sparse import csr_matrix     \n",
        "%matplotlib inline\n",
        "word_embed_layer = targetWord_model.layers[0]\n",
        "weights = word_embed_layer.get_weights()[0][1:]\n",
        "print(weights.shape)\n",
        "pd.DataFrame(weights, index=id2word.values()).head()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV2PgatuPAP3",
        "outputId": "e6ea8330-8b06-41ba-e432-32b998f7d8e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(9833, 9833)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'جان': ['تسلیم',\n",
              "  'بعث',\n",
              "  'نالان',\n",
              "  'مورش',\n",
              "  'معکم',\n",
              "  'اصطفای',\n",
              "  'عشق',\n",
              "  'ذاتی',\n",
              "  'پرعسل',\n",
              "  'قید',\n",
              "  'معارف',\n",
              "  'نامدشان',\n",
              "  'قبیحی',\n",
              "  'منزلش'],\n",
              " 'دل': ['المستغاث',\n",
              "  'بالطفی',\n",
              "  'دمیده',\n",
              "  'جراره',\n",
              "  'نالان',\n",
              "  'درغژم',\n",
              "  'رمیدستی',\n",
              "  'مردفکن',\n",
              "  'یرکن',\n",
              "  'افلاکی',\n",
              "  'القفا',\n",
              "  'پهنا',\n",
              "  'بارم',\n",
              "  'بودم'],\n",
              " 'عشق': ['نقدر',\n",
              "  'صبغنا',\n",
              "  'میذن',\n",
              "  'عنینه',\n",
              "  'ملاقات',\n",
              "  'القمر',\n",
              "  'آفرید',\n",
              "  'کربلا',\n",
              "  'بالاحسان',\n",
              "  'افزایش',\n",
              "  'ششه',\n",
              "  'تمنن',\n",
              "  'بوالفتوحی',\n",
              "  'ناسیه']}"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "\n",
        "distance_matrix = euclidean_distances(weights)\n",
        "print(distance_matrix.shape)\n",
        "\n",
        "similar_words = {search_term: [id2word[idx] for idx in distance_matrix[word2id[search_term]-1].argsort()[1:15]+1] \n",
        "                   for search_term in ['جان','عشق','دل']}\n",
        "\n",
        "similar_words"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "NLP_2wec.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMkg53AEbDgzKdOU2vZKVuS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}